{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tutorial for parameter estimation on simulated data with an injected GW150914-like signal","provenance":[{"file_id":"https://github.com/GregoryAshton/GWParameterEstimationWorkshop2020/blob/master/notebooks/parameter_estimation_injection_tutorial.ipynb","timestamp":1598599921151}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"Collapsed":"false","colab_type":"text","id":"OjUNeFsxyguu"},"source":["# Gravitational Wave Parameter-Estimation Workshop\n","\n","## Tutorial: Parameter estimation for a GW150914-like injection in simulated data\n","\n","(Note, this tutorial and the open-data tutorial (tutorial A) are based on the [GWOSC ODW #3 tutorial 2.4](https://github.com/gw-odw/odw-2020). You may wish to browse that repository for similar notebooks covering a range of gravitational-wave data analysis subjects). \n","\n","This example estimates the non-spinning parameters of an injected binary black hole system using\n","commonly used prior distributions. This will take about 40 minutes to run.\n","   \n","More examples at https://lscsoft.docs.ligo.org/bilby/examples.html"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","colab_type":"text","id":"VwsIdKJ3yguv"},"source":["##  Installation  (execute only if running on a cloud platform!)"]},{"cell_type":"code","metadata":{"Collapsed":"false","colab_type":"code","id":"eJeo4XrHyguw","colab":{}},"source":["# -- Use the following line in Google Colab\n","#! pip install -q 'lalsuite' 'bilby' 'gwpy' 'nestle'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"Collapsed":"false","colab_type":"text","id":"f0q3Y_9gygu0"},"source":["**Important:** With Google Colab, you may need to restart the runtime after running the cell above."]},{"cell_type":"markdown","metadata":{"Collapsed":"false","colab_type":"text","id":"XK8fHu13ygu1"},"source":["## Initialization\n","\n","We begin by importing some commonly used functions"]},{"cell_type":"code","metadata":{"Collapsed":"false","colab_type":"code","id":"HyRSGt6cygu2","colab":{}},"source":["from __future__ import division, print_function\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import bilby\n","from bilby.core.prior import Uniform\n","from bilby.gw.conversion import convert_to_lal_binary_black_hole_parameters, generate_all_bbh_parameters\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kebaay1_-VCl","colab_type":"text"},"source":["## Bilby version"]},{"cell_type":"code","metadata":{"id":"ce3X6j8_-VCm","colab_type":"code","colab":{}},"source":["print(bilby.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"Collapsed":"false","colab_type":"text","id":"_Hd4d4KVygu6"},"source":["## Creating fake data\n","In this notebook, we'll analyse GW150914-like injection. Our first task is to create some data!"]},{"cell_type":"markdown","metadata":{"id":"t_SF9Ka0-VCt","colab_type":"text"},"source":["Set up a random seed for result reproducibility.  This is optional!"]},{"cell_type":"code","metadata":{"Collapsed":"false","colab_type":"code","id":"1cUhLaFIygu6","colab":{}},"source":["np.random.seed(1234)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LeNFXNhk-VC0","colab_type":"text"},"source":["We now need to specify the parameters of our injection. You can set this up as a python dictionary"]},{"cell_type":"code","metadata":{"id":"0NS7dsbo-VC1","colab_type":"code","colab":{}},"source":["injection_parameters = dict(\n","    mass_1=36., mass_2=29., a_1=0.4, a_2=0.3, tilt_1=0.5, tilt_2=1.0,\n","    phi_12=1.7, phi_jl=0.3, luminosity_distance=4000., theta_jn=0.4, psi=2.659,\n","    phase=1.3, geocent_time=1126259642.413, ra=1.375, dec=-1.2108)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2O2IkK-s-VC9","colab_type":"text"},"source":["We also need to set up some additional arguments such as what waveform approximant to use and what the minimum frequencies for analysis are. This can again be set up as a python dictionary. While the duration and sampling frequenciy can be set up as variables."]},{"cell_type":"code","metadata":{"id":"oGbSBHKK-VC-","colab_type":"code","colab":{}},"source":["waveform_arguments = dict(waveform_approximant='IMRPhenomPv2',\n","                          reference_frequency=50., minimum_frequency=20., catch_waveform_errors=True)\n","duration = 4.\n","sampling_frequency = 2048."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcmwU4zS-VDJ","colab_type":"text"},"source":["We will now set up a bilby waveform generator. This wraps up some of the jobs of converting between parameters etc"]},{"cell_type":"code","metadata":{"id":"LGZ3FJEH-VDL","colab_type":"code","colab":{}},"source":["waveform_generator = bilby.gw.WaveformGenerator(\n","    duration=duration, sampling_frequency=sampling_frequency,\n","    frequency_domain_source_model=bilby.gw.source.lal_binary_black_hole,\n","    parameter_conversion=bilby.gw.conversion.convert_to_lal_binary_black_hole_parameters,\n","    waveform_arguments=waveform_arguments)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDjm_WWa-VDb","colab_type":"text"},"source":["We now set up the bilby interferometers and inject data"]},{"cell_type":"code","metadata":{"id":"DqXqt2_n-VDe","colab_type":"code","colab":{}},"source":["ifos = bilby.gw.detector.InterferometerList(['H1', 'L1'])\n","ifos.set_strain_data_from_power_spectral_densities(\n","    sampling_frequency=sampling_frequency, duration=duration,\n","    start_time=injection_parameters['geocent_time'] - 3)\n","injection = ifos.inject_signal(\n","    waveform_generator=waveform_generator,\n","    parameters=injection_parameters)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aHJl7KfR-VDn","colab_type":"text"},"source":["### Looking at the data\n","Okay, we have spent a bit of time now initializing things. Let's check that everything makes sense. To do this, we'll plot our analysis data alongwise the amplitude spectral density (ASD); this is just the square root of the PSD and has the right units to be comparable to the frequency-domain strain data. We also add the \"injection\", here we plot the absolute value of the (complex) plus polarization."]},{"cell_type":"code","metadata":{"id":"5X8dXgfe-VDp","colab_type":"code","colab":{}},"source":["H1 = ifos[0]\n","H1_injection = injection[0]\n","\n","fig, ax = plt.subplots()\n","idxs = H1.strain_data.frequency_mask  # This is a boolean mask of the frequencies which we'll use in the analysis\n","ax.loglog(H1.strain_data.frequency_array[idxs],\n","          np.abs(H1.strain_data.frequency_domain_strain[idxs]),\n","          label=\"data\")\n","ax.loglog(H1.frequency_array[idxs],\n","          H1.amplitude_spectral_density_array[idxs],\n","          label=\"ASD\")\n","ax.loglog(H1.frequency_array[idxs],\n","          np.abs(H1_injection[\"plus\"][idxs]),\n","          label=\"Abs. val. of plus polarization\")\n","ax.set_xlabel(\"Frequency [Hz]\")\n","ax.set_ylabel(\"Strain [strain/$\\sqrt{Hz}$]\")\n","ax.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BHmntnGC-VDz","colab_type":"text"},"source":["## Low dimensional analysis\n","\n","As in the open-data tutorial, we'll do a low-dimensional analysis."]},{"cell_type":"markdown","metadata":{"id":"-BOBg5PF-VD1","colab_type":"text"},"source":["### Create a prior\n","\n","Here, we create a prior fixing everything except the chirp mass, mass ratio and geocent_time parameters to fixed values. The first two we described above. The geocent_time is the time at which it merges."]},{"cell_type":"code","metadata":{"id":"i_L0CzpZ-VD2","colab_type":"code","colab":{}},"source":["prior = bilby.core.prior.PriorDict()\n","prior['chirp_mass'] = Uniform(name='chirp_mass', minimum=27.0,maximum=32.5)\n","prior['mass_ratio'] = Uniform(name='mass_ratio', minimum=0.5, maximum=1)\n","# We fix the rest of the parameters to their injected values\n","for key in ['a_1', 'a_2', 'tilt_1', 'tilt_2', 'phi_12', 'phi_jl', 'psi', 'ra',\n","            'dec','luminosity_distance', 'theta_jn', 'phase', 'geocent_time']:\n","    prior[key] = injection_parameters[key]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXjk6dYh-VD-","colab_type":"code","colab":{}},"source":["prior"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zevvjuE5-VEP","colab_type":"text"},"source":["## Create a likelihood\n","\n","For Bayesian inference, we need to evaluate the likelihood. In Bilby, we create a likelihood object. This is the communication interface between the sampling part of Bilby and the data. Explicitly, when Bilby is sampling it only uses the `parameters` and `log_likelihood()` of the likelihood object. This means the likelihood can be arbitrarily complicated and the sampling part of Bilby won't mind a bit!\n","\n","Let's create a `GravitationalWaveTransient`, a special inbuilt method carefully designed to wrap up evaluating the likelihood of a waveform model in some data."]},{"cell_type":"code","metadata":{"id":"L1A5gM9e-VER","colab_type":"code","colab":{}},"source":["likelihood = bilby.gw.likelihood.GravitationalWaveTransient(\n","    interferometers=ifos, waveform_generator=waveform_generator, priors=prior,\n","    time_marginalization=False, phase_marginalization=False, distance_marginalization=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JIH8trrW-VEd","colab_type":"text"},"source":["This will print a warning about the `start_time`, it is safe to ignore this.\n","\n","Here, we do not use any marginalization (we fixed these parameters to the injection values in the prior)"]},{"cell_type":"markdown","metadata":{"id":"rAQMkmOh-VEf","colab_type":"text"},"source":["### Run the analysis"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","colab_type":"text","id":"LCfygeVyygvM"},"source":["Now that the prior is set-up and the likelihood is set-up (with the data and the signal mode), we can run the sampler to get the posterior result. This function takes the likelihood and prior along with some options for how to do the sampling and how to save the data."]},{"cell_type":"code","metadata":{"Collapsed":"false","colab_type":"code","id":"HHS9JSX3ygvN","colab":{}},"source":["result_short = bilby.run_sampler(\n","    likelihood, prior, sampler='dynesty', outdir='short', label=\"GW150914\",\n","    conversion_function=bilby.gw.conversion.generate_all_bbh_parameters,\n","    nlive=500, dlogz=3,  # <- Arguments are used to make things fast - not recommended for general use\n","    clean=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_767bg3b-VEn","colab_type":"text"},"source":["### Looking at the outputs"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","colab_type":"text","id":"wKR045TIygvT"},"source":["The `run_sampler` returned `result_short` - this is a Bilby result object. The posterior samples are stored in a [pandas data frame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) (think of this like a spreadsheet), let's take a look at it"]},{"cell_type":"code","metadata":{"id":"tvlzeXz9-VEo","colab_type":"code","colab":{}},"source":["result_short.posterior"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fGCSzPUy-VEw","colab_type":"text"},"source":["We can pull out specific parameters that we are interested in"]},{"cell_type":"code","metadata":{"id":"JjaoMGOW-VEx","colab_type":"code","colab":{}},"source":["result_short.posterior[\"chirp_mass\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"auN_pn4s-VE2","colab_type":"text"},"source":["This returned another `pandas` object. If you just want to get the numbers as a numpy array run"]},{"cell_type":"code","metadata":{"id":"ayPS0wqE-VE3","colab_type":"code","colab":{}},"source":["Mc = result_short.posterior[\"chirp_mass\"].values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NXcbYaMl-VE9","colab_type":"text"},"source":["We can then get some useful quantities such as the 90\\% credible interval"]},{"cell_type":"code","metadata":{"id":"ZRAlpHZf-VE-","colab_type":"code","colab":{}},"source":["lower_bound = np.quantile(Mc, 0.05)\n","upper_bound = np.quantile(Mc, 0.95)\n","median = np.quantile(Mc, 0.5)\n","print(\"Mc = {} with a 90% C.I = {} -> {}\".format(median, lower_bound, upper_bound))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zuHlU9Go-VFD","colab_type":"text"},"source":["We can then plot the chirp mass in a histogram adding a region to indicate the 90\\% C.I."]},{"cell_type":"code","metadata":{"id":"bxVsKaqu-VFE","colab_type":"code","colab":{}},"source":["fig, ax = plt.subplots()\n","ax.hist(result_short.posterior[\"chirp_mass\"], bins=20)\n","ax.axvspan(lower_bound, upper_bound, color='C1', alpha=0.4)\n","ax.axvline(median, color='C1')\n","ax.set_xlabel(\"chirp mass\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tS9Z5fKP-VFV","colab_type":"text"},"source":["The result object also has in-built methods to make nice plots such as corner plots. You can add the priors if you are only plotting parameter which you sampled in, e.g."]},{"cell_type":"code","metadata":{"id":"3UsDVXUF-VFY","colab_type":"code","colab":{}},"source":["result_short.plot_corner(parameters=[\"chirp_mass\", \"mass_ratio\", \"geocent_time\"], prior=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SID9ApbV-VFj","colab_type":"text"},"source":["You can also plot lines indicating specific points. Here, we add the values recorded on [GWOSC](https://www.gw-openscience.org/events/GW150914/). Notably, these fall outside the bulk of the posterior uncertainty here. This is because we limited our prior - if instead we ran the full analysis these agree nicely."]},{"cell_type":"code","metadata":{"Collapsed":"false","colab_type":"code","id":"SB4AqmTaygvU","colab":{}},"source":["parameters = dict(mass_1=36, mass_2=29)\n","result_short.plot_corner(parameters)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_gfuXNik-VFy","colab_type":"text"},"source":["Earlier we discussed the \"correlation\" - in this plot we start to see the correlation between $m_1$ and $m_2$."]},{"cell_type":"markdown","metadata":{"id":"mNzoVEMq-VF1","colab_type":"text"},"source":["### Meta data\n","The result object also stores meta data, like the priors"]},{"cell_type":"code","metadata":{"id":"lUHVzMZy-VF3","colab_type":"code","colab":{}},"source":["result_short.priors"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rTX2uUCG-VF9","colab_type":"text"},"source":["and details of the analysis itself:"]},{"cell_type":"code","metadata":{"id":"fvAz8exL-VGN","colab_type":"code","colab":{}},"source":["result_short.sampler_kwargs[\"nlive\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J7luFxed-VGW","colab_type":"text"},"source":["Finally, we can also get out the Bayes factor for the signal vs. Gaussian noise:"]},{"cell_type":"code","metadata":{"id":"-AfoZAXI-VGX","colab_type":"code","colab":{}},"source":["print(\"ln Bayes factor = {} +/- {}\".format(\n","    result_short.log_bayes_factor, result_short.log_evidence_err))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1W_uFn76-VGb","colab_type":"text"},"source":["## Challenge questions\n","\n","* Rerun the analysis with a different samler. *Hint: [see the docs](https://lscsoft.docs.ligo.org/bilby/samplers.html#switching-between-samplers)*. This may require you to install a new sampler!\n","* Rerun the analysis with time marginalization. This will require you to change the prior to a uniform prior centered on the simulation value."]}]}